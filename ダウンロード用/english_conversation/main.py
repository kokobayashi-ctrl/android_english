import streamlit as st
import os
import time
from time import sleep
from pathlib import Path
from streamlit.components.v1 import html
from langchain.memory import ConversationSummaryBufferMemory
from langchain.chains import ConversationChain
from langchain.prompts import (
    ChatPromptTemplate,
    HumanMessagePromptTemplate,
    MessagesPlaceholder,
)
from langchain.schema import SystemMessage
from openai import OpenAI
from langchain_openai import ChatOpenAI
from dotenv import load_dotenv
import functions as ft
import constants as ct


# å„ç¨®è¨­å®š
load_dotenv()
st.set_page_config(
    page_title=ct.APP_NAME
)

# ã‚¿ã‚¤ãƒˆãƒ«è¡¨ç¤º
st.markdown(f"## {ct.APP_NAME}")

# åˆæœŸå‡¦ç†
if "messages" not in st.session_state:
    st.session_state.messages = []
    st.session_state.start_flg = False
    st.session_state.pre_mode = ""
    st.session_state.shadowing_flg = False
    st.session_state.shadowing_button_flg = False
    st.session_state.shadowing_count = 0
    st.session_state.shadowing_first_flg = True
    st.session_state.shadowing_audio_input_flg = False
    st.session_state.shadowing_evaluation_first_flg = True
    st.session_state.dictation_flg = False
    st.session_state.dictation_button_flg = False
    st.session_state.dictation_count = 0
    st.session_state.dictation_first_flg = True
    st.session_state.dictation_chat_message = ""
    st.session_state.dictation_evaluation_first_flg = True
    st.session_state.chat_open_flg = False
    st.session_state.problem = ""
    st.session_state.learned_phrases = []
    st.session_state.reaction_practice_flg = False
    st.session_state.phrase_learning_flg = False
    st.session_state.assistance_flg = False
    st.session_state.japanese_voice_input = ""
    st.session_state.japanese_voice_processed = False
    
    st.session_state.openai_obj = OpenAI(api_key=os.environ["OPENAI_API_KEY"])
    st.session_state.llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0.5)
    st.session_state.memory = ConversationSummaryBufferMemory(
        llm=st.session_state.llm,
        max_token_limit=1000,
        return_messages=True
    )

    # ãƒ¢ãƒ¼ãƒ‰ã€Œæ—¥å¸¸è‹±ä¼šè©±ã€ç”¨ã®Chainä½œæˆ
    st.session_state.chain_basic_conversation = ft.create_chain(ct.SYSTEM_TEMPLATE_BASIC_CONVERSATION)

# åˆæœŸè¡¨ç¤º
# col1, col2, col3, col4 = st.columns([1, 1, 1, 2])
# æå‡ºèª²é¡Œç”¨
col1, col2, col3, col4 = st.columns([2, 2, 3, 3])
with col1:
    if st.session_state.start_flg:
        st.button("é–‹å§‹", use_container_width=True, type="primary")
    else:
        st.session_state.start_flg = st.button("é–‹å§‹", use_container_width=True, type="primary")
with col2:
    st.session_state.speed = st.selectbox(label="å†ç”Ÿé€Ÿåº¦", options=ct.PLAY_SPEED_OPTION, index=3, label_visibility="collapsed")
with col3:
    st.session_state.mode = st.selectbox(label="ãƒ¢ãƒ¼ãƒ‰", options=[ct.MODE_1, ct.MODE_2, ct.MODE_3, ct.MODE_4, ct.MODE_5], label_visibility="collapsed")
    # ãƒ¢ãƒ¼ãƒ‰ã‚’å¤‰æ›´ã—ãŸéš›ã®å‡¦ç†
    if st.session_state.mode != st.session_state.pre_mode:
        # è‡ªå‹•ã§ãã®ãƒ¢ãƒ¼ãƒ‰ã®å‡¦ç†ãŒå®Ÿè¡Œã•ã‚Œãªã„ã‚ˆã†ã«ã™ã‚‹
        st.session_state.start_flg = False
        # ã€Œæ—¥å¸¸è‹±ä¼šè©±ã€é¸æŠæ™‚ã®åˆæœŸåŒ–å‡¦ç†
        if st.session_state.mode == ct.MODE_1:
            st.session_state.dictation_flg = False
            st.session_state.shadowing_flg = False
        # ã€Œã‚·ãƒ£ãƒ‰ãƒ¼ã‚¤ãƒ³ã‚°ã€é¸æŠæ™‚ã®åˆæœŸåŒ–å‡¦ç†
        st.session_state.shadowing_count = 0
        if st.session_state.mode == ct.MODE_2:
            st.session_state.dictation_flg = False
        # ã€Œãƒ‡ã‚£ã‚¯ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã€é¸æŠæ™‚ã®åˆæœŸåŒ–å‡¦ç†
        st.session_state.dictation_count = 0
        if st.session_state.mode == ct.MODE_3:
            st.session_state.shadowing_flg = False
        # ã€Œãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ç·´ç¿’ã€é¸æŠæ™‚ã®åˆæœŸåŒ–å‡¦ç†
        if st.session_state.mode == ct.MODE_4:
            st.session_state.dictation_flg = False
            st.session_state.shadowing_flg = False
        # ã€Œãƒ•ãƒ¬ãƒ¼ã‚ºå­¦ç¿’ã€é¸æŠæ™‚ã®åˆæœŸåŒ–å‡¦ç†
        if st.session_state.mode == ct.MODE_5:
            st.session_state.dictation_flg = False
            st.session_state.shadowing_flg = False
        # ãƒãƒ£ãƒƒãƒˆå…¥åŠ›æ¬„ã‚’éè¡¨ç¤ºã«ã™ã‚‹
        st.session_state.chat_open_flg = False
    st.session_state.pre_mode = st.session_state.mode
with col4:
    st.session_state.englv = st.selectbox(label="è‹±èªãƒ¬ãƒ™ãƒ«", options=ct.ENGLISH_LEVEL_OPTION, label_visibility="collapsed")

# ã‚¢ã‚·ã‚¹ãƒˆæ©Ÿèƒ½ã®UIï¼ˆå¸¸ã«è¡¨ç¤ºï¼‰
st.divider()
with st.expander("ğŸ†˜ è‹±èªè¡¨ç¾ã‚¢ã‚·ã‚¹ãƒˆæ©Ÿèƒ½", expanded=False):
    st.info("è‹±èªã§è¡¨ç¾ã§ããªã„æ™‚ã¯ã€æ—¥æœ¬èªã§è¦æœ›ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚AIãŒé©åˆ‡ãªè‹±èªè¡¨ç¾ã‚’ææ¡ˆã—ã¾ã™ã€‚")
    
    # å…¥åŠ›æ–¹æ³•ã®é¸æŠ
    input_method = st.radio(
        "å…¥åŠ›æ–¹æ³•ã‚’é¸æŠã—ã¦ãã ã•ã„",
        ["ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›", "ğŸ¤ éŸ³å£°å…¥åŠ›"],
        horizontal=True,
        key="assistance_input_method"
    )
    
    if input_method == "ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›":
        col1, col2 = st.columns([3, 1])
        with col1:
            japanese_request = st.text_input(
                "æ—¥æœ¬èªã§è¦æœ›ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
                placeholder="ä¾‹: ã€ŒãŠç–²ã‚Œæ§˜ã§ã™ã€ã‚’è‹±èªã§è¨€ã„ãŸã„",
                key="japanese_assistance_input"
            )
        with col2:
            assistance_button = st.button("ğŸ” è‹±èªè¡¨ç¾ã‚’ææ¡ˆ", use_container_width=True)
    
    else:  # éŸ³å£°å…¥åŠ›
        st.markdown("**éŸ³å£°å…¥åŠ›ã§æ—¥æœ¬èªã®è¦æœ›ã‚’è©±ã—ã¦ãã ã•ã„**")
        
        # éŸ³å£°å…¥åŠ›ãƒœã‚¿ãƒ³
        if st.button("ğŸ¤ æ—¥æœ¬èªã§éŸ³å£°å…¥åŠ›", use_container_width=True, type="primary", key="japanese_voice_button"):
            # éŸ³å£°å…¥åŠ›ã‚’å—ã‘å–ã£ã¦éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
            audio_input_file_path = f"{ct.AUDIO_INPUT_DIR}/japanese_audio_input_{int(time.time())}.wav"
            ft.record_audio(audio_input_file_path)
            
            # éŸ³å£°å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æ—¥æœ¬èªæ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
            with st.spinner('æ—¥æœ¬èªéŸ³å£°ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›ä¸­...'):
                transcript = ft.transcribe_audio_japanese(audio_input_file_path)
                japanese_request = transcript.text
            
            # éŸ³å£°å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜
            st.session_state.japanese_voice_input = japanese_request
            st.session_state.japanese_voice_processed = True
            st.rerun()
        
        # éŸ³å£°èªè­˜çµæœã®è¡¨ç¤º
        if hasattr(st.session_state, 'japanese_voice_input') and st.session_state.japanese_voice_input:
            st.markdown("---")
            st.markdown("**ğŸ¯ éŸ³å£°èªè­˜çµæœ**")
            st.info(f"ã€Œ{st.session_state.japanese_voice_input}ã€")
            
            col1, col2 = st.columns([1, 1])
            with col1:
                if st.button("ğŸ” ã“ã®å†…å®¹ã§è‹±èªè¡¨ç¾ã‚’ææ¡ˆ", use_container_width=True, key="use_voice_input", type="primary"):
                    japanese_request = st.session_state.japanese_voice_input
                    assistance_button = True
                else:
                    assistance_button = False
            with col2:
                if st.button("ğŸ”„ éŸ³å£°å…¥åŠ›ã‚’ã‚„ã‚Šç›´ã™", use_container_width=True, key="retry_voice_input"):
                    if hasattr(st.session_state, 'japanese_voice_input'):
                        del st.session_state.japanese_voice_input
                    if hasattr(st.session_state, 'japanese_voice_processed'):
                        del st.session_state.japanese_voice_processed
                    st.rerun()
        else:
            assistance_button = False
    
    if assistance_button and japanese_request:
        with st.spinner("è‹±èªè¡¨ç¾ã‚’ç”Ÿæˆä¸­..."):
            assistance_result = ft.get_english_assistance(japanese_request)
        
        st.markdown("**è‹±èªè¡¨ç¾ã®ææ¡ˆ:**")
        st.markdown(assistance_result)
        
        # ææ¡ˆã•ã‚ŒãŸè¡¨ç¾ã‚’å­¦ç¿’ãƒ•ãƒ¬ãƒ¼ã‚ºã¨ã—ã¦ä¿å­˜ã™ã‚‹ã‚ªãƒ—ã‚·ãƒ§ãƒ³
        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸ’¾ ã“ã®è¡¨ç¾ã‚’å­¦ç¿’ãƒ•ãƒ¬ãƒ¼ã‚ºã«è¿½åŠ ", key="save_assisted_phrase"):
                # åŸºæœ¬è¡¨ç¾ã‚’æŠ½å‡ºã—ã¦ä¿å­˜ï¼ˆç°¡å˜ãªå®Ÿè£…ï¼‰
                lines = assistance_result.split('\n')
                basic_phrase = ""
                for line in lines:
                    if "ã€åŸºæœ¬è¡¨ç¾ã€‘" in line or (line.strip().startswith('-') and not line.strip().startswith('ã€')):
                        basic_phrase = line.strip().replace('- ', '').replace('ã€åŸºæœ¬è¡¨ç¾ã€‘', '').strip()
                        if basic_phrase:
                            break
                
                if basic_phrase:
                    ft.save_assisted_phrase(basic_phrase, japanese_request, "ã‚¢ã‚·ã‚¹ãƒˆæ©Ÿèƒ½ã§ç”Ÿæˆ")
                    st.success("å­¦ç¿’ãƒ•ãƒ¬ãƒ¼ã‚ºã«è¿½åŠ ã—ã¾ã—ãŸï¼")
                    st.rerun()
                else:
                    st.warning("åŸºæœ¬è¡¨ç¾ã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚æ‰‹å‹•ã§è¿½åŠ ã—ã¦ãã ã•ã„ã€‚")
        
        with col2:
            if st.button("ğŸ”Š éŸ³å£°ã§ç·´ç¿’", key="practice_assisted_phrase"):
                # åŸºæœ¬è¡¨ç¾ã‚’æŠ½å‡ºã—ã¦éŸ³å£°å†ç”Ÿ
                lines = assistance_result.split('\n')
                basic_phrase = ""
                for line in lines:
                    if "ã€åŸºæœ¬è¡¨ç¾ã€‘" in line or (line.strip().startswith('-') and not line.strip().startswith('ã€')):
                        basic_phrase = line.strip().replace('- ', '').replace('ã€åŸºæœ¬è¡¨ç¾ã€‘', '').strip()
                        if basic_phrase:
                            break
                
                if basic_phrase:
                    with st.spinner("éŸ³å£°ã‚’ç”Ÿæˆä¸­..."):
                        phrase_audio = st.session_state.openai_obj.audio.speech.create(
                            model="tts-1",
                            voice="alloy",
                            input=basic_phrase
                        )
                        temp_audio_path = f"{ct.AUDIO_OUTPUT_DIR}/temp_assisted_phrase.wav"
                        ft.save_to_wav(phrase_audio.content, temp_audio_path)
                        ft.play_wav(temp_audio_path, speed=st.session_state.speed)
                    st.success(f"ã€Œ{basic_phrase}ã€ã‚’éŸ³å£°ã§ç·´ç¿’ã—ã¾ã—ãŸï¼")
                else:
                    st.warning("åŸºæœ¬è¡¨ç¾ã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
        
        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆã«è¿½åŠ 
        st.session_state.messages.append({"role": "user", "content": f"ã€æ—¥æœ¬èªè¦æœ›ã€‘{japanese_request}"})
        st.session_state.messages.append({"role": "assistant", "content": assistance_result})

with st.chat_message("assistant", avatar="images/ai_icon.jpg"):
    st.markdown("ã“ã¡ã‚‰ã¯ç”ŸæˆAIã«ã‚ˆã‚‹éŸ³å£°è‹±ä¼šè©±ã®ç·´ç¿’ã‚¢ãƒ—ãƒªã§ã™ã€‚ä½•åº¦ã‚‚ç¹°ã‚Šè¿”ã—ç·´ç¿’ã—ã€è‹±èªåŠ›ã‚’ã‚¢ãƒƒãƒ—ã•ã›ã¾ã—ã‚‡ã†ã€‚")
    st.markdown("**ã€æ“ä½œèª¬æ˜ã€‘**")
    st.success("""
    - ãƒ¢ãƒ¼ãƒ‰ã¨å†ç”Ÿé€Ÿåº¦ã‚’é¸æŠã—ã€ã€Œè‹±ä¼šè©±é–‹å§‹ã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦è‹±ä¼šè©±ã‚’å§‹ã‚ã¾ã—ã‚‡ã†ã€‚
    - ãƒ¢ãƒ¼ãƒ‰ã¯ã€Œæ—¥å¸¸è‹±ä¼šè©±ã€ã€Œã‚·ãƒ£ãƒ‰ãƒ¼ã‚¤ãƒ³ã‚°ã€ã€Œãƒ‡ã‚£ã‚¯ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã€ã€Œãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ç·´ç¿’ã€ã€Œãƒ•ãƒ¬ãƒ¼ã‚ºå­¦ç¿’ã€ã‹ã‚‰é¸ã¹ã¾ã™ã€‚
    - ç™ºè©±å¾Œã€5ç§’é–“æ²ˆé»™ã™ã‚‹ã“ã¨ã§éŸ³å£°å…¥åŠ›ãŒå®Œäº†ã—ã¾ã™ã€‚
    - ã€Œä¸€æ™‚ä¸­æ–­ã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã™ã“ã¨ã§ã€è‹±ä¼šè©±ã‚’ä¸€æ™‚ä¸­æ–­ã§ãã¾ã™ã€‚
    """)
st.divider()

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«å­¦ç¿’ã—ãŸãƒ•ãƒ¬ãƒ¼ã‚ºã‚’è¡¨ç¤º
with st.sidebar:
    st.header("ğŸ“š å­¦ç¿’ã—ãŸãƒ•ãƒ¬ãƒ¼ã‚º")
    
    if "learned_phrases" in st.session_state and st.session_state.learned_phrases:
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥è¡¨ç¤º
        selected_category = st.selectbox(
            "ã‚«ãƒ†ã‚´ãƒªã§ãƒ•ã‚£ãƒ«ã‚¿",
            ["å…¨ã¦"] + list(ct.PHRASE_CATEGORIES.keys()),
            key="phrase_category_filter"
        )
        
        # ãƒ•ãƒ¬ãƒ¼ã‚ºä¸€è¦§è¡¨ç¤º
        phrases_to_show = st.session_state.learned_phrases
        if selected_category != "å…¨ã¦":
            phrases_to_show = [p for p in st.session_state.learned_phrases if p["category"] == selected_category]
        
        for i, phrase_data in enumerate(phrases_to_show):
            with st.expander(f"{phrase_data['phrase'][:30]}...", expanded=False):
                st.write(f"**ãƒ•ãƒ¬ãƒ¼ã‚º**: {phrase_data['phrase']}")
                st.write(f"**ã‚«ãƒ†ã‚´ãƒª**: {ct.PHRASE_CATEGORIES.get(phrase_data['category'], phrase_data['category'])}")
                st.write(f"**å­¦ç¿’æ—¥**: {phrase_data['learned_date'][:10]}")
                st.write(f"**ç·´ç¿’å›æ•°**: {phrase_data['practice_count']}")
                
                # ç¿’å¾—åº¦ã®æ›´æ–°
                mastery_level = st.selectbox(
                    "ç¿’å¾—åº¦",
                    [0, 1, 2],
                    index=phrase_data['mastery_level'],
                    key=f"mastery_{i}",
                    format_func=lambda x: ["æœªç¿’å¾—", "å­¦ç¿’ä¸­", "ç¿’å¾—æ¸ˆã¿"][x]
                )
                
                if mastery_level != phrase_data['mastery_level']:
                    ft.update_phrase_mastery(phrase_data['phrase'], mastery_level)
                    st.rerun()
                
                # ãƒ•ãƒ¬ãƒ¼ã‚ºã®éŸ³å£°å†ç”Ÿ
                if st.button(f"ğŸ”Š éŸ³å£°å†ç”Ÿ", key=f"play_{i}"):
                    phrase_audio = st.session_state.openai_obj.audio.speech.create(
                        model="tts-1",
                        voice="alloy",
                        input=phrase_data['phrase']
                    )
                    temp_audio_path = f"{ct.AUDIO_OUTPUT_DIR}/temp_phrase_{i}.wav"
                    ft.save_to_wav(phrase_audio.content, temp_audio_path)
                    ft.play_wav(temp_audio_path, speed=st.session_state.speed)
    else:
        st.info("ã¾ã å­¦ç¿’ã—ãŸãƒ•ãƒ¬ãƒ¼ã‚ºãŒã‚ã‚Šã¾ã›ã‚“ã€‚ãƒ•ãƒ¬ãƒ¼ã‚ºå­¦ç¿’ãƒ¢ãƒ¼ãƒ‰ã§æ–°ã—ã„ãƒ•ãƒ¬ãƒ¼ã‚ºã‚’å­¦ç¿’ã—ã¾ã—ã‚‡ã†ï¼")
    
    # å­¦ç¿’çµ±è¨ˆ
    if "learned_phrases" in st.session_state and st.session_state.learned_phrases:
        st.header("ğŸ“Š å­¦ç¿’çµ±è¨ˆ")
        stats = ft.get_phrase_statistics()
        
        col1, col2 = st.columns(2)
        with col1:
            st.metric("ç·ãƒ•ãƒ¬ãƒ¼ã‚ºæ•°", stats['total'])
        with col2:
            mastered = stats['mastery_levels']['2']
            st.metric("ç¿’å¾—æ¸ˆã¿", mastered)
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥ã‚°ãƒ©ãƒ•
        if stats['by_category']:
            st.bar_chart(stats['by_category'])

# ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆã®ä¸€è¦§è¡¨ç¤º
for message in st.session_state.messages:
    if message["role"] == "assistant":
        with st.chat_message(message["role"], avatar="images/ai_icon.jpg"):
            st.markdown(message["content"])
    elif message["role"] == "user":
        with st.chat_message(message["role"], avatar="images/user_icon.jpg"):
            st.markdown(message["content"])
    else:
        st.divider()

# LLMãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®ä¸‹éƒ¨ã«ãƒ¢ãƒ¼ãƒ‰å®Ÿè¡Œã®ãƒœã‚¿ãƒ³è¡¨ç¤º
if st.session_state.shadowing_flg:
    st.session_state.shadowing_button_flg = st.button("ã‚·ãƒ£ãƒ‰ãƒ¼ã‚¤ãƒ³ã‚°é–‹å§‹")
if st.session_state.dictation_flg:
    st.session_state.dictation_button_flg = st.button("ãƒ‡ã‚£ã‚¯ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³é–‹å§‹")

# ã€Œãƒ‡ã‚£ã‚¯ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã€ãƒ¢ãƒ¼ãƒ‰ã®ãƒãƒ£ãƒƒãƒˆå…¥åŠ›å—ä»˜æ™‚ã«å®Ÿè¡Œ
if st.session_state.chat_open_flg:
    st.info("AIãŒèª­ã¿ä¸Šã’ãŸéŸ³å£°ã‚’ã€ç”»é¢ä¸‹éƒ¨ã®ãƒãƒ£ãƒƒãƒˆæ¬„ã‹ã‚‰ãã®ã¾ã¾å…¥åŠ›ãƒ»é€ä¿¡ã—ã¦ãã ã•ã„ã€‚")

st.session_state.dictation_chat_message = st.chat_input("â€»ã€Œãƒ‡ã‚£ã‚¯ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã€é¸æŠæ™‚ä»¥å¤–ã¯é€ä¿¡ä¸å¯")

if st.session_state.dictation_chat_message and not st.session_state.chat_open_flg:
    st.stop()

# ã€Œè‹±ä¼šè©±é–‹å§‹ã€ãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚ŒãŸå ´åˆã®å‡¦ç†
if st.session_state.start_flg:

    # ãƒ¢ãƒ¼ãƒ‰ï¼šã€Œãƒ‡ã‚£ã‚¯ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã€
    # ã€Œãƒ‡ã‚£ã‚¯ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã€ãƒœã‚¿ãƒ³æŠ¼ä¸‹æ™‚ã‹ã€ã€Œè‹±ä¼šè©±é–‹å§‹ã€ãƒœã‚¿ãƒ³æŠ¼ä¸‹æ™‚ã‹ã€ãƒãƒ£ãƒƒãƒˆé€ä¿¡æ™‚
    if st.session_state.mode == ct.MODE_3 and (st.session_state.dictation_button_flg or st.session_state.dictation_count == 0 or st.session_state.dictation_chat_message):
        if st.session_state.dictation_first_flg:
            st.session_state.chain_create_problem = ft.create_chain(ct.SYSTEM_TEMPLATE_CREATE_PROBLEM)
            st.session_state.dictation_first_flg = False
        # ãƒãƒ£ãƒƒãƒˆå…¥åŠ›ä»¥å¤–
        if not st.session_state.chat_open_flg:
            with st.spinner('å•é¡Œæ–‡ç”Ÿæˆä¸­...'):
                st.session_state.problem, llm_response_audio = ft.create_problem_and_play_audio()

            st.session_state.chat_open_flg = True
            st.session_state.dictation_flg = False
            st.rerun()
        # ãƒãƒ£ãƒƒãƒˆå…¥åŠ›æ™‚ã®å‡¦ç†
        else:
            # ãƒãƒ£ãƒƒãƒˆæ¬„ã‹ã‚‰å…¥åŠ›ã•ã‚ŒãŸå ´åˆã«ã®ã¿è©•ä¾¡å‡¦ç†ãŒå®Ÿè¡Œã•ã‚Œã‚‹ã‚ˆã†ã«ã™ã‚‹
            if not st.session_state.dictation_chat_message:
                st.stop()
            
            # AIãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ç”»é¢è¡¨ç¤º
            with st.chat_message("assistant", avatar=ct.AI_ICON_PATH):
                st.markdown(st.session_state.problem)
            with st.chat_message("user", avatar=ct.USER_ICON_PATH):
                st.markdown(st.session_state.dictation_chat_message)

            # LLMãŒç”Ÿæˆã—ãŸå•é¡Œæ–‡ã¨ãƒãƒ£ãƒƒãƒˆå…¥åŠ›å€¤ã‚’ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆã«è¿½åŠ 
            st.session_state.messages.append({"role": "assistant", "content": st.session_state.problem})
            st.session_state.messages.append({"role": "user", "content": st.session_state.dictation_chat_message})
            
            with st.spinner('è©•ä¾¡çµæœã®ç”Ÿæˆä¸­...'):
                system_template = ct.SYSTEM_TEMPLATE_EVALUATION.format(
                    llm_text=st.session_state.problem,
                    user_text=st.session_state.dictation_chat_message
                )
                st.session_state.chain_evaluation = ft.create_chain(system_template)
                # å•é¡Œæ–‡ã¨å›ç­”ã‚’æ¯”è¼ƒã—ã€è©•ä¾¡çµæœã®ç”Ÿæˆã‚’æŒ‡ç¤ºã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆ
                llm_response_evaluation = ft.create_evaluation()
            
            # è©•ä¾¡çµæœã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆã¸ã®è¿½åŠ ã¨è¡¨ç¤º
            with st.chat_message("assistant", avatar=ct.AI_ICON_PATH):
                st.markdown(llm_response_evaluation)
            st.session_state.messages.append({"role": "assistant", "content": llm_response_evaluation})
            st.session_state.messages.append({"role": "other"})
            
            # å„ç¨®ãƒ•ãƒ©ã‚°ã®æ›´æ–°
            st.session_state.dictation_flg = True
            st.session_state.dictation_chat_message = ""
            st.session_state.dictation_count += 1
            st.session_state.chat_open_flg = False

            st.rerun()

    
    # ãƒ¢ãƒ¼ãƒ‰ï¼šã€Œæ—¥å¸¸è‹±ä¼šè©±ã€
    if st.session_state.mode == ct.MODE_1:
        # éŸ³å£°å…¥åŠ›ã‚’å—ã‘å–ã£ã¦éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
        audio_input_file_path = f"{ct.AUDIO_INPUT_DIR}/audio_input_{int(time.time())}.wav"
        ft.record_audio(audio_input_file_path)

        # éŸ³å£°å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
        with st.spinner('éŸ³å£°å…¥åŠ›ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›ä¸­...'):
            transcript = ft.transcribe_audio(audio_input_file_path)
            audio_input_text = transcript.text

        # éŸ³å£°å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã®ç”»é¢è¡¨ç¤º
        with st.chat_message("user", avatar=ct.USER_ICON_PATH):
            st.markdown(audio_input_text)

        with st.spinner("å›ç­”ã®éŸ³å£°èª­ã¿ä¸Šã’æº–å‚™ä¸­..."):
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›å€¤ã‚’LLMã«æ¸¡ã—ã¦å›ç­”å–å¾—
            llm_response = st.session_state.chain_basic_conversation.predict(input=audio_input_text)
            
            # LLMã‹ã‚‰ã®å›ç­”ã‚’éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã«å¤‰æ›
            llm_response_audio = st.session_state.openai_obj.audio.speech.create(
                model="tts-1",
                voice="alloy",
                input=llm_response
            )

            # ä¸€æ—¦mp3å½¢å¼ã§éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆå¾Œã€wavå½¢å¼ã«å¤‰æ›
            audio_output_file_path = f"{ct.AUDIO_OUTPUT_DIR}/audio_output_{int(time.time())}.wav"
            ft.save_to_wav(llm_response_audio.content, audio_output_file_path)

        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿ä¸Šã’
        ft.play_wav(audio_output_file_path, speed=st.session_state.speed)

        # AIãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ç”»é¢è¡¨ç¤ºã¨ãƒªã‚¹ãƒˆã¸ã®è¿½åŠ 
        with st.chat_message("assistant", avatar=ct.AI_ICON_PATH):
            st.markdown(llm_response)

        # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›å€¤ã¨LLMã‹ã‚‰ã®å›ç­”ã‚’ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ä¸€è¦§ã«è¿½åŠ 
        st.session_state.messages.append({"role": "user", "content": audio_input_text})
        st.session_state.messages.append({"role": "assistant", "content": llm_response})


    # ãƒ¢ãƒ¼ãƒ‰ï¼šã€Œã‚·ãƒ£ãƒ‰ãƒ¼ã‚¤ãƒ³ã‚°ã€
    # ã€Œã‚·ãƒ£ãƒ‰ãƒ¼ã‚¤ãƒ³ã‚°ã€ãƒœã‚¿ãƒ³æŠ¼ä¸‹æ™‚ã‹ã€ã€Œè‹±ä¼šè©±é–‹å§‹ã€ãƒœã‚¿ãƒ³æŠ¼ä¸‹æ™‚
    if st.session_state.mode == ct.MODE_2 and (st.session_state.shadowing_button_flg or st.session_state.shadowing_count == 0 or st.session_state.shadowing_audio_input_flg):
        if st.session_state.shadowing_first_flg:
            st.session_state.chain_create_problem = ft.create_chain(ct.SYSTEM_TEMPLATE_CREATE_PROBLEM)
            st.session_state.shadowing_first_flg = False
        
        if not st.session_state.shadowing_audio_input_flg:
            with st.spinner('å•é¡Œæ–‡ç”Ÿæˆä¸­...'):
                st.session_state.problem, llm_response_audio = ft.create_problem_and_play_audio()

        # éŸ³å£°å…¥åŠ›ã‚’å—ã‘å–ã£ã¦éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
        st.session_state.shadowing_audio_input_flg = True
        audio_input_file_path = f"{ct.AUDIO_INPUT_DIR}/audio_input_{int(time.time())}.wav"
        ft.record_audio(audio_input_file_path)
        st.session_state.shadowing_audio_input_flg = False

        with st.spinner('éŸ³å£°å…¥åŠ›ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›ä¸­...'):
            # éŸ³å£°å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
            transcript = ft.transcribe_audio(audio_input_file_path)
            audio_input_text = transcript.text

        # AIãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ç”»é¢è¡¨ç¤º
        with st.chat_message("assistant", avatar=ct.AI_ICON_PATH):
            st.markdown(st.session_state.problem)
        with st.chat_message("user", avatar=ct.USER_ICON_PATH):
            st.markdown(audio_input_text)
        
        # LLMãŒç”Ÿæˆã—ãŸå•é¡Œæ–‡ã¨éŸ³å£°å…¥åŠ›å€¤ã‚’ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆã«è¿½åŠ 
        st.session_state.messages.append({"role": "assistant", "content": st.session_state.problem})
        st.session_state.messages.append({"role": "user", "content": audio_input_text})

        with st.spinner('è©•ä¾¡çµæœã®ç”Ÿæˆä¸­...'):
            if st.session_state.shadowing_evaluation_first_flg:
                system_template = ct.SYSTEM_TEMPLATE_EVALUATION.format(
                    llm_text=st.session_state.problem,
                    user_text=audio_input_text
                )
                st.session_state.chain_evaluation = ft.create_chain(system_template)
                st.session_state.shadowing_evaluation_first_flg = False
            # å•é¡Œæ–‡ã¨å›ç­”ã‚’æ¯”è¼ƒã—ã€è©•ä¾¡çµæœã®ç”Ÿæˆã‚’æŒ‡ç¤ºã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆ
            llm_response_evaluation = ft.create_evaluation()
        
        # è©•ä¾¡çµæœã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆã¸ã®è¿½åŠ ã¨è¡¨ç¤º
        with st.chat_message("assistant", avatar=ct.AI_ICON_PATH):
            st.markdown(llm_response_evaluation)
        st.session_state.messages.append({"role": "assistant", "content": llm_response_evaluation})
        st.session_state.messages.append({"role": "other"})
        
        # å„ç¨®ãƒ•ãƒ©ã‚°ã®æ›´æ–°
        st.session_state.shadowing_flg = True
        st.session_state.shadowing_count += 1

        # ã€Œã‚·ãƒ£ãƒ‰ãƒ¼ã‚¤ãƒ³ã‚°ã€ãƒœã‚¿ãƒ³ã‚’è¡¨ç¤ºã™ã‚‹ãŸã‚ã«å†æç”»
        st.rerun()

    # ãƒ¢ãƒ¼ãƒ‰ï¼šã€Œãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ç·´ç¿’ã€
    if st.session_state.mode == ct.MODE_4:
        if not st.session_state.reaction_practice_flg:
            # ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ç·´ç¿’ç”¨ã®Chainä½œæˆ
            st.session_state.chain_reaction_practice = ft.create_reaction_practice_chain()
            st.session_state.reaction_practice_flg = True
        
        # éŸ³å£°å…¥åŠ›ã‚’å—ã‘å–ã£ã¦éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
        audio_input_file_path = f"{ct.AUDIO_INPUT_DIR}/audio_input_{int(time.time())}.wav"
        ft.record_audio(audio_input_file_path)

        # éŸ³å£°å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
        with st.spinner('éŸ³å£°å…¥åŠ›ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›ä¸­...'):
            transcript = ft.transcribe_audio(audio_input_file_path)
            audio_input_text = transcript.text

        # éŸ³å£°å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã®ç”»é¢è¡¨ç¤º
        with st.chat_message("user", avatar=ct.USER_ICON_PATH):
            st.markdown(audio_input_text)

        with st.spinner("ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ç·´ç¿’ã®æº–å‚™ä¸­..."):
            # ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’ä¿ƒã™ç™ºè©±ã‚’ç”Ÿæˆ
            reaction_prompt = st.session_state.chain_reaction_practice.predict(input="")
            
            # ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ç™ºè©±ã‚’éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã«å¤‰æ›
            reaction_audio = st.session_state.openai_obj.audio.speech.create(
                model="tts-1",
                voice="alloy",
                input=reaction_prompt
            )

            # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆã¨å†ç”Ÿ
            audio_output_file_path = f"{ct.AUDIO_OUTPUT_DIR}/audio_output_{int(time.time())}.wav"
            ft.save_to_wav(reaction_audio.content, audio_output_file_path)
            ft.play_wav(audio_output_file_path, speed=st.session_state.speed)

        # AIãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ç”»é¢è¡¨ç¤º
        with st.chat_message("assistant", avatar=ct.AI_ICON_PATH):
            st.markdown(reaction_prompt)

        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’è©•ä¾¡ã—ã€é©åˆ‡ãªãƒ•ãƒ¬ãƒ¼ã‚ºã‚’ææ¡ˆ
        with st.spinner("ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³è©•ä¾¡ä¸­..."):
            evaluation_prompt = f"""
            ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³: "{audio_input_text}"
            å…ƒã®ç™ºè©±: "{reaction_prompt}"
            
            ã“ã®ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãŒé©åˆ‡ã‹ã©ã†ã‹è©•ä¾¡ã—ã€ã‚ˆã‚Šè‡ªç„¶ãªãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ•ãƒ¬ãƒ¼ã‚ºã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚
            ã¾ãŸã€ã“ã®ã‚·ãƒãƒ¥ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã§ä½¿ãˆã‚‹ä»–ã®ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ•ãƒ¬ãƒ¼ã‚ºã‚‚æ•™ãˆã¦ãã ã•ã„ã€‚
            
            ã‚‚ã—ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãŒä¸é©åˆ‡ãªå ´åˆã‚„ã€ã‚ˆã‚Šè‰¯ã„è¡¨ç¾ãŒã‚ã‚‹å ´åˆã¯ã€
            å…·ä½“çš„ãªæ”¹å–„æ¡ˆã¨ã€ãªãœãã®è¡¨ç¾ãŒè‰¯ã„ã®ã‹ã®ç†ç”±ã‚‚å«ã‚ã¦ãã ã•ã„ã€‚
            """
            
            evaluation_response = st.session_state.openai_obj.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": evaluation_prompt}],
                temperature=0.7
            )
            
            evaluation_text = evaluation_response.choices[0].message.content

        # è©•ä¾¡çµæœã®è¡¨ç¤º
        with st.chat_message("assistant", avatar=ct.AI_ICON_PATH):
            st.markdown(evaluation_text)

        # å­¦ç¿’ã—ãŸãƒ•ãƒ¬ãƒ¼ã‚ºã‚’ä¿å­˜
        if "Really?" in audio_input_text or "That's" in audio_input_text or "No way!" in audio_input_text:
            ft.save_learned_phrase(audio_input_text, "reactions", f"ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ç·´ç¿’ã§ã®ä½¿ç”¨")

        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆã«è¿½åŠ 
        st.session_state.messages.append({"role": "user", "content": audio_input_text})
        st.session_state.messages.append({"role": "assistant", "content": reaction_prompt})
        st.session_state.messages.append({"role": "assistant", "content": evaluation_text})

    # ãƒ¢ãƒ¼ãƒ‰ï¼šã€Œãƒ•ãƒ¬ãƒ¼ã‚ºå­¦ç¿’ã€
    if st.session_state.mode == ct.MODE_5:
        if not st.session_state.phrase_learning_flg:
            # ãƒ•ãƒ¬ãƒ¼ã‚ºå­¦ç¿’ç”¨ã®Chainä½œæˆ
            st.session_state.chain_phrase_learning = ft.create_phrase_learning_chain()
            st.session_state.phrase_learning_flg = True
        
        with st.spinner("ãƒ•ãƒ¬ãƒ¼ã‚ºç”Ÿæˆä¸­..."):
            # æ–°ã—ã„ãƒ•ãƒ¬ãƒ¼ã‚ºã‚’ç”Ÿæˆ
            new_phrases = st.session_state.chain_phrase_learning.predict(input="")
            
            # ç”Ÿæˆã•ã‚ŒãŸãƒ•ãƒ¬ãƒ¼ã‚ºã‚’éŸ³å£°ã§èª­ã¿ä¸Šã’
            phrases_audio = st.session_state.openai_obj.audio.speech.create(
                model="tts-1",
                voice="alloy",
                input=new_phrases
            )

            # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆã¨å†ç”Ÿ
            audio_output_file_path = f"{ct.AUDIO_OUTPUT_DIR}/audio_output_{int(time.time())}.wav"
            ft.save_to_wav(phrases_audio.content, audio_output_file_path)
            ft.play_wav(audio_output_file_path, speed=st.session_state.speed)

        # ãƒ•ãƒ¬ãƒ¼ã‚ºã®è¡¨ç¤º
        with st.chat_message("assistant", avatar=ct.AI_ICON_PATH):
            st.markdown(new_phrases)

        # ãƒ•ãƒ¬ãƒ¼ã‚ºã‚’ã‚«ãƒ†ã‚´ãƒªåˆ¥ã«ä¿å­˜
        phrases_list = new_phrases.split('\n')
        for phrase in phrases_list:
            if phrase.strip() and not phrase.strip().startswith('#'):
                # ã‚«ãƒ†ã‚´ãƒªã‚’è‡ªå‹•åˆ¤å®šï¼ˆç°¡å˜ãªä¾‹ï¼‰
                category = "reactions"
                if "?" in phrase:
                    category = "questions"
                elif "!" in phrase:
                    category = "emotions"
                elif "joke" in phrase.lower() or "funny" in phrase.lower():
                    category = "humor"
                
                ft.save_learned_phrase(phrase.strip(), category, "ãƒ•ãƒ¬ãƒ¼ã‚ºå­¦ç¿’ã§ç”Ÿæˆ")

        # å­¦ç¿’çµ±è¨ˆã®è¡¨ç¤º
        stats = ft.get_phrase_statistics()
        with st.expander("å­¦ç¿’çµ±è¨ˆ", expanded=False):
            st.write(f"**ç·å­¦ç¿’ãƒ•ãƒ¬ãƒ¼ã‚ºæ•°**: {stats['total']}")
            st.write("**ã‚«ãƒ†ã‚´ãƒªåˆ¥**:")
            for category, count in stats['by_category'].items():
                st.write(f"- {ct.PHRASE_CATEGORIES.get(category, category)}: {count}")
            st.write("**ç¿’å¾—åº¦åˆ¥**:")
            st.write(f"- æœªç¿’å¾—: {stats['mastery_levels']['0']}")
            st.write(f"- å­¦ç¿’ä¸­: {stats['mastery_levels']['1']}")
            st.write(f"- ç¿’å¾—æ¸ˆã¿: {stats['mastery_levels']['2']}")

        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆã«è¿½åŠ 
        st.session_state.messages.append({"role": "assistant", "content": new_phrases})